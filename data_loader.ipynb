{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'racah'\n",
    "import h5py\n",
    "import numpy as np\n",
    "from operator import mul\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from multiprocessing import Pool\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#1 is hur\n",
    "#0 is nhur\n",
    "class LoadHurricane():\n",
    "    def __init__(self,batch_size=None, flatten=False, num_ims=None, seed=4):\n",
    "        self.seed = seed\n",
    "        self.batch_size = batch_size\n",
    "        self.num_ims = num_ims\n",
    "        self.seed = seed\n",
    "        self.flatten=flatten\n",
    "    #TODO try on 96x96 (use bigger file -> get from cori)\n",
    "    def load_hurricane(self, path, use_negative=True):\n",
    "    \n",
    "        print 'getting data...'\n",
    "        h5f = h5py.File(path)\n",
    "        if not self.num_ims:\n",
    "            hurs = h5f['hurricane'][:]\n",
    "            nhurs = h5f['nothurricane'][:]\n",
    "            hur_boxes = h5f['hurricane_box'][:]\n",
    "        else:\n",
    "            hurs = h5f['hurricane'][:self.num_ims / 2]\n",
    "            nhurs = h5f['nothurricane'][:self.num_ims / 2]\n",
    "            hur_boxes = h5f['hurricane_box'][:self.num_ims / 2]\n",
    "            \n",
    "        hurs_bboxes = np.asarray(hur_boxes).reshape(hurs.shape[0],4)\n",
    "        nhurs_bboxes = np.zeros((nhurs.shape[0],4))\n",
    "\n",
    "        if use_negative:\n",
    "            inputs = np.vstack((hurs,nhurs))\n",
    "            bboxes = np.vstack((hurs_bboxes,nhurs_bboxes))\n",
    "        else:\n",
    "            inputs = hurs\n",
    "            bboxes = hurs_bboxes\n",
    "\n",
    " \n",
    "        cl_labels = np.zeros((inputs.shape[0]))\n",
    "        cl_labels[:hurs.shape[0]] = 1\n",
    "        if not self.num_ims:\n",
    "            self.num_ims = inputs.shape[0]\n",
    "\n",
    "        print self.num_ims\n",
    "\n",
    "\n",
    "        tr_i, te_i, val_i = self.get_train_val_test_ix(self.num_ims)\n",
    "\n",
    "        return self.set_up_train_test_val(inputs, bboxes, cl_labels, tr_i, te_i, val_i)\n",
    "\n",
    "\n",
    "\n",
    "    def get_train_val_test_ix(self, num_ims):\n",
    "        # tr, te, val is 0.6,0.2,0.2\n",
    "        ix = range(num_ims)\n",
    "\n",
    "        n_te = int(0.2*num_ims)\n",
    "        n_val = int(0.25*(num_ims - n_te))\n",
    "        n_tr =  num_ims - n_te - n_val\n",
    "\n",
    "\n",
    "        #shuffle once deterministically\n",
    "        np.random.RandomState(3).shuffle(ix)\n",
    "        te_i = ix[:n_te]\n",
    "        rest = ix[n_te:]\n",
    "\n",
    "        np.random.RandomState(self.seed).shuffle(rest)\n",
    "        val_i = rest[:n_val]\n",
    "        tr_i = rest[n_val:n_val + n_tr]\n",
    "        return tr_i, te_i, val_i\n",
    "\n",
    "\n",
    "    def set_up_train_test_val(self,hurs, boxes,cl_labels, tr_i,te_i, val_i):\n",
    "\n",
    "        x_tr, bbox_tr, lbl_tr = hurs[tr_i], boxes[tr_i], cl_labels[tr_i]\n",
    "        x_tr, tr_means, tr_stds = self.preprocess_each_channel(x_tr)\n",
    "        #self.test_masks(bbox_tr, y_tr,np.random.randint(x_tr.shape[0]))\n",
    "        x_te,bbox_te, lbl_te = hurs[te_i], boxes[te_i], cl_labels[te_i]\n",
    "        x_te, _ ,_ = self.preprocess_each_channel(x_te)\n",
    "\n",
    "        #self.test_masks(bbox_te, y_te,np.random.randint(x_te.shape[0]))\n",
    "        x_val, bbox_val, lbl_val = hurs[val_i], boxes[val_i], cl_labels[val_i]\n",
    "        x_val, _ ,_ = self.preprocess_each_channel(x_val)\n",
    "        #self.test_masks(bbox_val, y_val,np.random.randint(x_val.shape[0]))\n",
    "\n",
    "        if self.flatten:\n",
    "            x_tr = x_tr.reshape(x_tr.shape[0], reduce(mul, x_tr.shape[1:]))\n",
    "            x_te = x_te.reshape(x_te.shape[0], reduce(mul, x_te.shape[1:]))\n",
    "            x_val = x_val.reshape(x_val.shape[0], reduce(mul, x_val.shape[1:]))\n",
    "\n",
    "        x_dims = hurs.shape[1:]\n",
    "\n",
    "        return {'tr': (x_tr, bbox_tr, lbl_tr), \\\n",
    "        'te':(x_te,  bbox_te, lbl_te), \\\n",
    "        'val': (x_val ,bbox_val, lbl_val)}\n",
    "        # return {'x_train': x_tr, 'y_train': y_tr, 'x_test': x_te, 'y_test': y_te,'x_val':x_val, 'y_val':y_val, 'boxes': boxes}\n",
    "\n",
    "    def preprocess_each_channel(self,arr, means=[], stds=[], mode='normalize'):\n",
    "        # assumes channels are on the axis 1\n",
    "        if len(means) == 0:\n",
    "            means = np.mean(arr, axis=(0, 2, 3))\n",
    "        if mode == 'standardize':\n",
    "            if len(stds) == 0:\n",
    "                stds = np.std(arr, axis=(0, 2, 3))\n",
    "            for channel, (mean, std) in enumerate(zip(means, stds)):\n",
    "                arr[:, channel, :, :] -= mean\n",
    "                arr[:, channel, :, :] /= std\n",
    "            return arr, means, stds\n",
    "        elif mode == \"normalize\":\n",
    "\n",
    "            for channel, mean in enumerate(means):\n",
    "                arr[:, channel, :, :] -= mean\n",
    "                \n",
    "            mins = np.min(arr, axis=(0, 2, 3))\n",
    "            maxes = np.max(arr, axis=(0, 2, 3))\n",
    "            #normalize between -1 and 1\n",
    "            for channel, (min_,max_) in enumerate(zip(mins, maxes)):\n",
    "                arr[:, channel, :, :] = 2 * ((arr[:, channel, :, :] - min_) / (max_ - min_)) - 1\n",
    "            return arr, None, None\n",
    "\n",
    "                \n",
    "            \n",
    "       \n",
    "        \n",
    "\n",
    "    def get_cooords(self, bbox):\n",
    "        hmin, hmax, wmin, wmax = bbox[1],bbox[3], bbox[0],bbox[2]\n",
    "        return hmin, hmax, wmin, wmax\n",
    "\n",
    "    \n",
    "#TODO: load a classification dataset and a localization one   \n",
    "def load_dataset(num_ims=None, path='/global/project/projectdirs/nervana/yunjie/dataset/localization/larger_hurricanes_loc.h5'):\n",
    "    lh = LoadHurricane(num_ims=num_ims)\n",
    "    dataset_dict = lh.load_hurricane(path, use_negative=True)\n",
    "    \n",
    "    datasets = [(dataset_dict[k][0],dataset_dict[k][2]) for k in ['tr', 'val','te']]\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = datasets\n",
    "\n",
    "    y_train, y_val, y_test = [y.astype('int32') for y in [y_train, y_val, y_test]]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data...\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
      "  1.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.]\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test=load_dataset(num_ims=40)\n",
    "\n",
    "    import matplotlib\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    from matplotlib import pyplot as plt\n",
    "\n",
    "    print y_train\n",
    "\n",
    "    for i in range(20):\n",
    "        g = plt.subplot(5,4,i+1)\n",
    "        g.set_xlabel(str(y_train[i]))\n",
    "        g.imshow(X_train[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
