{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "import argparse\n",
    "\n",
    "from scripts.nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from notebooks/run_dir.ipynb\n",
      "importing Jupyter notebook from notebooks/helper_fxns.ipynb\n",
      "importing Jupyter notebook from notebooks/data_loader.ipynb\n",
      "importing Jupyter notebook from notebooks/print_n_plot.ipynb\n",
      "importing Jupyter notebook from notebooks/build_network.ipynb\n",
      "importing Jupyter notebook from notebooks/netcdf_loader.ipynb\n"
     ]
    }
   ],
   "source": [
    "'''before we import theano anywhere else we want to make sure we specify \n",
    "a unique directory for compiling, so we dont get into a locking issue\n",
    "if we run multiple hur_mains at once on a global file system. Haven't truly implementedthis yet '''\n",
    "from notebooks.run_dir import create_run_dir\n",
    "from notebooks.helper_fxns import dump_hyperparams\n",
    "from notebooks.data_loader import load_data, load_precomputed_data\n",
    "#from notebooks.train_val import train\n",
    "from notebooks.print_n_plot import plot_ims_with_boxes\n",
    "from notebooks.build_network import build_network\n",
    "from notebooks.netcdf_loader import bbox_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if inside a notebook, then get rid of weird notebook arguments, so that arg parsing still works\n",
    "if any([\"jupyter\" in arg for arg in sys.argv]):\n",
    "    sys.argv=sys.argv[:1]\n",
    "    \n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('-e', '--epochs', type=int, default=10000,\n",
    "    help='number of epochs for training')\n",
    "\n",
    "parser.add_argument('-l', '--learn_rate', default=0.00001, type=float,\n",
    "    help='the learning rate for the network')\n",
    "\n",
    "parser.add_argument('-n', '--num_ims', default=6, type=int,\n",
    "    help='number of total images')\n",
    "\n",
    "parser.add_argument('-f', '--num_filters', default=2, type=int,\n",
    "    help='number of filters in each conv layer')\n",
    "\n",
    "parser.add_argument( '--fc', default=512, type=int,\n",
    "    help='number of fully connected units')\n",
    "\n",
    "parser.add_argument('--coord_penalty', default=5, type=int,\n",
    "    help='penalty for guessing coordinates wrong')\n",
    "\n",
    "parser.add_argument('--size_penalty', default=5, type=int,\n",
    "    help='penalty for guessing height or width wrong')\n",
    "\n",
    "parser.add_argument('--nonobj_penalty', default=0.5, type=float,\n",
    "    help='penalty for guessing an object where one isnt')\n",
    "\n",
    "parser.add_argument('-c','--num_extra_conv', default=0, type=int,\n",
    "    help='conv layers to add on to each conv layer before max pooling')\n",
    "\n",
    "parser.add_argument('--num_convpool', default=4, type=int,\n",
    "    help='number of conv layer-pool layer pairs')\n",
    "\n",
    "parser.add_argument('--momentum', default=0.9, type=float,\n",
    "    help='momentum')\n",
    "\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "from notebooks.helper_fxns import early_stop\n",
    "import logging\n",
    "\n",
    "\n",
    "\n",
    "class TrainVal(object):\n",
    "    def __init__(self, iterator, tr_kwargs, val_kwargs, num_epochs, fns, save_path, n_ims_to_plot=6):\n",
    "        self.train_errs, self.train_accs, self.val_errs, self.val_accs = [], [], [], []\n",
    "        self.iterator = iterator\n",
    "        self.tr_kwargs = tr_kwargs\n",
    "        self.val_kwargs = val_kwargs\n",
    "        self.num_epochs = num_epochs\n",
    "        self.tr_fn, self.val_fn, self.box_fn = fns\n",
    "        self.n_ims_to_plot = n_ims_to_plot\n",
    "        self.logger = self.setup_logging(save_path)\n",
    "        self.epoch = 0\n",
    "        self.start_time = 0\n",
    "        self.seed = 5\n",
    "        self.save_path = save_path\n",
    "    def train_one_epoch(self):\n",
    "        self.epoch += 1\n",
    "        self.start_time = time.time()\n",
    "        tr_err = 0\n",
    "        tr_acc = 0\n",
    "        tr_batches = 0\n",
    "        start_time = time.time()\n",
    "        for x,y in self.iterator(**self.tr_kwargs):\n",
    "            x= np.squeeze(x,axis=2)\n",
    "            y = np.squeeze(y,axis=1)\n",
    "            tr_err += self.tr_fn(x,y)\n",
    "            _, acc = self.val_fn(x,y)\n",
    "            tr_acc += acc\n",
    "            tr_batches += 1\n",
    "        \n",
    "\n",
    "        self.train_errs.append(tr_err / tr_batches)\n",
    "        self.train_accs.append(tr_acc / tr_batches)\n",
    "        self.print_results(tr_err / tr_batches, tr_acc / tr_batches, \"train\")\n",
    "    \n",
    "    def val_one_epoch(self):\n",
    "        self.start_time = time.time()\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for x,y in self.iterator(**self.val_kwargs):\n",
    "            x= np.squeeze(x,axis=2)\n",
    "            y = np.squeeze(y,axis=1)\n",
    "            err, acc = val_fn(x,y)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        self.val_errs.append(val_err / val_batches)\n",
    "        self.val_accs.append(val_acc / val_batches)\n",
    "        self.print_results(val_err / val_batches, val_acc / val_batches,'val')\n",
    "        \n",
    "\n",
    "    def print_results(self, err, acc, typ=\"train\"):\n",
    "        if typ == \"train\":\n",
    "            self.logger.info(\"Epoch {} of {} took {:.3f}s\".format(self.epoch, self.num_epochs, time.time() - self.start_time))\n",
    "        elif typ == \"val\":\n",
    "            self.logger.info(\"\\tValidation took {:.3f}s\".format(time.time() - self.start_time))\n",
    "        self.logger.info(\"\\t\\t\" + typ + \" los:\\t\\t{:.4f}\".format(err))\n",
    "        self.logger.info(\"\\t\\t\" + typ + \"acc:\\t\\t{:.4f} %\".format(acc * 100))\n",
    "    \n",
    "\n",
    "    def plot_learn_curve(self):\n",
    "        self._plot_learn_curve('err')\n",
    "        self._plot_learn_curve('acc')\n",
    "        \n",
    "    def _plot_learn_curve(self,type_):\n",
    "        plt.figure(1 if type_== 'err' else 2)\n",
    "        plt.clf()\n",
    "        plt.title('Train/Val %s' %(type_))\n",
    "        tr_arr = self.train_errs if type_ == 'err' else self.train_accs\n",
    "        val_arr = self.val_errs if type_ == 'err' else self.val_accs\n",
    "        plt.plot(tr_arr, label='train ' + type_)\n",
    "        plt.plot(val_arr, label='val' + type_)\n",
    "        plt.legend( loc = 'center left', bbox_to_anchor = (1.0, 0.5),\n",
    "           ncol=2)\n",
    "\n",
    "        plt.savefig(\"%s/%s_learning_curve.png\"%(self.save_path,type_))\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "#     def plot_ims_with_boxes(n_ims):\n",
    "#         for x,y in self.tr_iterator:\n",
    "#             im = x[0]\n",
    "            \n",
    "#     def _plot_im_with_boxes(ims, pred_bboxes, gt_bboxes, sanity_boxes=None):\n",
    "#         #bbox of form center x,y,w,h\n",
    "#         n_ims = ims.shape[0]\n",
    "#         channels = ims.shape[1]\n",
    "#         plt.figure(1, figsize=(80,80))\n",
    "\n",
    "#         #sanity boxes is the original bounding boxes\n",
    "#         if sanity_boxes is not None:\n",
    "#             assert np.isclose(gt_bboxes, sanity_boxes).all()\n",
    "\n",
    "#         count=0\n",
    "#         for i in range(n_ims):\n",
    "#             for j in range(channels):  \n",
    "#                 count+= 1\n",
    "#                 sp = plt.subplot(n_ims,channels, count)\n",
    "#                 sp.imshow(ims[i,j])\n",
    "#                 add_bbox(sp, pred_bboxes[i], color='r')\n",
    "#                 add_bbox(sp, gt_bboxes[i], color='g')\n",
    "#         if save_plots:\n",
    "#             plt.savefig(\"%s/epoch_%i_boxes.png\"%(self.save_path,self.epoch))\n",
    "#             plt.savefig(\"%s/boxes.png\"%(path))\n",
    "#             plt.show()\n",
    "#         else:\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "#     def add_bbox(subplot, bbox, color):\n",
    "#         #box of form center x,y  w,h\n",
    "#         x,y,w,h = bbox\n",
    "#         subplot.add_patch(patches.Rectangle(\n",
    "#         xy=(x - w / 2. , y - h / 2.),\n",
    "#         width=w,\n",
    "#         height=h, lw=2,\n",
    "#         fill=False, color=color))\n",
    "\n",
    "\n",
    "    def setup_logging(self,save_path):\n",
    "        logger = logging.getLogger('simple_example')\n",
    "        logger.setLevel(logging.DEBUG)\n",
    "        # create file handler which logs even debug messages\n",
    "        fh = logging.FileHandler('%s/training.log'%(save_path))\n",
    "        fh.setLevel(logging.DEBUG)\n",
    "        # create console handler with a higher log level\n",
    "        ch = logging.StreamHandler()\n",
    "        ch.setLevel(logging.DEBUG)\n",
    "        logger.addHandler(ch)\n",
    "        logger.addHandler(fh)\n",
    "        return logger\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def train(iterator, network,\n",
    "          fns, \n",
    "          num_epochs, \n",
    "          num_ims=20,\n",
    "          save_weights=False, \n",
    "          save_path='./results', \n",
    "          load_path=None):\n",
    "    \n",
    "    \n",
    "    print \"Starting training...\" \n",
    "    \n",
    "    tr_kwargs = dict(years=[1979], days=num_ims)\n",
    "    val_kwargs= dict(years=[1980], days=int(0.2*num_ims))\n",
    "    \n",
    "    tv = TrainVal(bbox_iterator, tr_kwargs,val_kwargs, num_epochs, fns, save_path)\n",
    "    for epoch in range(num_epochs):\n",
    "        tv.train_one_epoch()\n",
    "        tv.val_one_epoch()\n",
    "        if epoch % 1 == 0:\n",
    "            tv.plot_learn_curve()\n",
    "        #if epoch % 100\n",
    "            \n",
    "        \n",
    "        \n",
    "\n",
    "#             if epoch % 100 == 0 or epoch < 100:\n",
    "#                 pred_boxes, gt_boxes = box_fn(x_tr,y_tr)              \n",
    "#                 plot_ims_with_boxes(x_tr[inds], pred_boxes[inds], gt_boxes[inds], epoch=epoch,\n",
    "#                                     save_plots=save_plots, path=save_path)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "#         if save_weights and epoch % 10 == 0:\n",
    "  \n",
    "#             np.savez('%s/model.npz'%(save_path), *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_dir = create_run_dir()\n",
    "print run_dir\n",
    "\n",
    "\n",
    "\n",
    "'''set params'''\n",
    "network_kwargs = {'learning_rate': args.learn_rate, \n",
    "                  'input_shape': (None,16,768,1152),\n",
    "                  'dropout_p': 0, \n",
    "                  'weight_decay': 0, \n",
    "                  'num_filters': args.num_filters, \n",
    "                  'num_fc_units': args.fc, \n",
    "                  'num_convpool': args.num_convpool,\n",
    "                  'num_extra_conv': args.num_extra_conv,\n",
    "                  'momentum': args.momentum,\n",
    "                  'coord_penalty': args.coord_penalty,\n",
    "                  'nonobj_penalty': args.nonobj_penalty,\n",
    "                   }\n",
    "\n",
    "\n",
    "'''get network and train_fns'''\n",
    "train_fn, val_fn, box_fn,pred_fn, network, hyperparams = build_network(**network_kwargs)\n",
    "\n",
    "hyperparams.update({'num_ims': args.num_ims, 'tr_size': args.num_ims})\n",
    "'''save hyperparams'''\n",
    "dump_hyperparams(hyperparams, path=run_dir)\n",
    "\n",
    "'''train'''\n",
    "train(bbox_iterator, network=network, fns=(train_fn, val_fn, box_fn),num_ims=args.num_ims, save_weights=True, num_epochs=args.epochs, save_path=run_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "deeplearning (fast)",
   "language": "python",
   "name": "deeplearning_fast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
