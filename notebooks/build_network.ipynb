{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from helper_fxns.ipynb\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.objectives import *\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "from lasagne.nonlinearities import *\n",
    "from lasagne.objectives import *\n",
    "from lasagne.layers import dnn\n",
    "from helper_fxns import get_detec_loss,get_all_boxes, get_MAP, softmax3D, softmax4D\n",
    "import copy\n",
    "#if __name__ == \"__main__\":\n",
    "    #from data_loader import load_classification_dataset, load_detection_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_hyperparams(frame):\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    #return dict(zip(args,values))\n",
    "    #del values['frame']\n",
    "    return values\n",
    "\n",
    "def build_network(kwargs):\n",
    "    \n",
    "    '''Takes a pretrained classification net and adds a few convolutional layers on top of it\n",
    "    and defines a detection loss function'''\n",
    "    '''Args:\n",
    "                      \n",
    "                      num_convpool: number of conv layer-pool layer pairs\n",
    "                      delta: smoothing constant to loss function (ie sqrt(x + delta)) \n",
    "                            -> if x is 0 gradient is undefined\n",
    "                      num_filters\n",
    "                      num_fc_units\n",
    "                      num_extra_conv: conv layers to add on to each conv layer before max pooling\n",
    "                      nonlinearity: which nonlinearity to use throughout\n",
    "                      n_boxes: how many boxes should be predicted at each grid point,\n",
    "                      nclass: how many classes are we predicting,\n",
    "                      grid_size: size of the grid that encodes various \n",
    "                                locations of image (ie in the YOLO paper they use 7x7 grid)\n",
    "                      w_init: weight intitialization\n",
    "                      dropout_p: prob of dropping unit\n",
    "                      coord_penalty : penalty in YOLO loss function for getting coordinates wrong\n",
    "                      nonobj_penalty: penalty in YOLO loss for guessing object when there isn't one\n",
    "                      learning_rate\n",
    "                      weight_decay\n",
    "                      momentum\n",
    "                      load: whether to load weights or not\n",
    "                      load_path: path for loading weights'''\n",
    "\n",
    "    if kwargs[\"3D\"]:\n",
    "        input_var = T.tensor5('input_var') \n",
    "    else:\n",
    "        input_var = T.tensor4('input_var')\n",
    "    target_var = T.tensor4('target_var') #is of shape (grid_size, grid_size,(n_boxes* 5 + nclass)\n",
    "    \n",
    "    print \"Building model and compiling functions...\" \n",
    "    \n",
    "    #make layers\n",
    "    networks = build_layers(input_var,kwargs)\n",
    "    \n",
    "    #load in any pretrained weights\n",
    "    if kwargs['ae_load_path'] != \"None\":\n",
    "        networks['ae'] = load_weights(kwargs['ae_load_path'], networks['ae'])\n",
    "        \n",
    "    if kwargs['yolo_load_path'] != \"None\":\n",
    "        networks['yolo'] = load_weights(kwargs['yolo_load_path'], networks['yolo'])\n",
    "    \n",
    "    #compile theano functions\n",
    "    fns = make_fns(networks, input_var, target_var, kwargs)\n",
    "     \n",
    "\n",
    "    return fns, networks\n",
    "\n",
    "\n",
    "def build_layers(input_var, nk):\n",
    "    '''nk: network_kwargs'''\n",
    "    '''conv, extra_convs, pool multiple times then fc with dropout, fc with dropout and softmax then reshape'''\n",
    "    \n",
    "    '''total number of conv layers is num_convpool * (1 + num_extra_conv)'''\n",
    "    \n",
    "    filter_dim = nk['filter_dim']\n",
    "    num_layers = nk['num_layers']\n",
    "    \n",
    "\n",
    "    filters_list = [128, 256, 512, 768, 1024, 1280]\n",
    "    conv = lasagne.layers.InputLayer(shape=nk['input_shape'])\n",
    "    for i in range(num_layers):\n",
    "\n",
    "        \n",
    "        num_filters = int(nk[\"filters_scale\"] * filters_list[i])\n",
    "\n",
    "        \n",
    "        if nk[\"3D\"]:\n",
    "            conv = dnn.Conv3DDNNLayer(conv, num_filters=num_filters, filter_size=(3,5,5),pad=(1,2,2), stride=(1,2,2)) \n",
    "        else:\n",
    "            conv = Conv2DLayer(conv, \n",
    "                                  num_filters=num_filters, \n",
    "                                  filter_size=nk['filter_dim'], \n",
    "                                  pad=nk['filter_dim'] / 2, \n",
    "                                  stride=2,\n",
    "                                  W=nk['w_init'], \n",
    "                                  nonlinearity=nk['nonlinearity'])\n",
    "\n",
    "        \n",
    "\n",
    "    encoder = conv\n",
    "    \n",
    "    \n",
    " \n",
    "    if nk[\"yolo_batch_norm\"]:\n",
    "        encoder = BatchNormLayer(encoder)\n",
    "    \n",
    "    if nk[\"3D\"]:\n",
    "            #encoder = FeaturePoolLayer(encoder, pool_size=640, axis=1)\n",
    "            box_conf = dnn.Conv3DDNNLayer(encoder, num_filters=2, filter_size=(3,3,3), \n",
    "                                          stride=(2,1,1), pad=(1,1,1), nonlinearity=softmax4D)\n",
    "    \n",
    "            #box_conf = NonlinearityLayer(box_conf, softmax4D)\n",
    "            class_conf = dnn.Conv3DDNNLayer(encoder, num_filters=nk['num_classes'], filter_size=(3,3,3), stride=(2,1,1), pad=(1,1,1), nonlinearity=softmax4D)\n",
    "            #class_conf = NonlinearityLayer(class_conf, softmax4D)\n",
    "            coord_net = dnn.Conv3DDNNLayer(encoder, num_filters=4, filter_size=(3,3,3), stride=(2,1,1), pad=(1,1,1), W=nk['w_init'],\n",
    "                            nonlinearity=rectify)\n",
    "            #outputs a batch_size x 10 x 4 x 12 x 18 \n",
    "            bbox_reg = ConcatLayer([coord_net,box_conf, class_conf])\n",
    "            #print get_output_shape(bbox_reg,input_shapes=(1,16,8,768,1152))\n",
    "            s = get_output_shape(bbox_reg)\n",
    "            # reshape to be like the 2D case -> batch_size*time_steps(4) x 10 x 12 x 18\n",
    "            net = ExpressionLayer(bbox_reg, function=lambda g: g.transpose((0,2,1,3,4)),\n",
    "                                  output_shape=(nk[\"batch_size\"],s[2], s[1],s[3], s[4]))\n",
    "            #print get_output_shape(net,input_shapes=(1,16,8,768,1152))\n",
    "            # after transpose\n",
    "            s = get_output_shape(net)\n",
    "            bbox_reg = ReshapeLayer(net, shape=(nk[\"batch_size\"]*s[1], s[2],s[3], s[4]))\n",
    "            #print get_output_shape(bbox_reg,input_shapes=(1,16,8,768,1152))\n",
    "            \n",
    "            \n",
    "    \n",
    "    else:   \n",
    "        box_conf = Conv2DLayer(encoder, num_filters=2, filter_size=3, pad=1, nonlinearity=linear)\n",
    "        box_conf = NonlinearityLayer(box_conf, softmax3D)\n",
    "        class_conf = Conv2DLayer(encoder, num_filters=nk['num_classes'], filter_size=3, pad=1, nonlinearity=linear)\n",
    "        class_conf = NonlinearityLayer(class_conf, softmax3D)\n",
    "        coord_net = Conv2DLayer(encoder, num_filters=4, filter_size=3,pad=1, W=nk['w_init'],\n",
    "                                nonlinearity=rectify)\n",
    "    \n",
    "    \n",
    "        bbox_reg = ConcatLayer([coord_net,box_conf, class_conf])\n",
    "    \n",
    "    for layer in get_all_layers(conv)[::-1]:\n",
    "        \n",
    "        if nk[\"batch_norm\"]:\n",
    "            conv = batch_norm(conv)\n",
    "        if isinstance(layer, InputLayer):\n",
    "            break\n",
    "        \n",
    "        conv = InverseLayer(conv, layer)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    return {'yolo': bbox_reg, 'ae':conv}#, \"decoder\":decoder_layers}\n",
    "        \n",
    "\n",
    "def load_weights(pickle_file_path, network):\n",
    "    '''grabs weights from an npz file'''\n",
    "    old_params = pickle.load(open(pickle_file_path, 'r'))\n",
    "\n",
    "    set_all_param_values(network, old_params)\n",
    "    return network\n",
    "    \n",
    "\n",
    "def make_fns(networks,input_var, target_var, kwargs ):\n",
    "    '''Compiles theano train, test, box_fns'''\n",
    "    #deterministic determines whether to use dropout or not in forward pass\n",
    "    #transpose output to match what loss expects\n",
    "    for k,v in networks.iteritems():\n",
    "        kwargs['logger'].info(\"\\n\" + k + \": \\n\")\n",
    "        for lay in get_all_layers(v):\n",
    "            kwargs[\"logger\"].info(str(lay) + \", \" + str(get_output_shape(lay)))\n",
    "    \n",
    "    yolo = networks['yolo']\n",
    "    ae = networks['ae']\n",
    "    yolo_test_prediction = lasagne.layers.get_output(yolo, deterministic=True, inputs=input_var)\n",
    "    yolo_prediction = lasagne.layers.get_output(yolo, deterministic=False,inputs=input_var)\n",
    "    \n",
    "    ae_test_prediction = lasagne.layers.get_output(ae, deterministic=True,inputs=input_var)\n",
    "    ae_prediction = lasagne.layers.get_output(ae, deterministic=False,inputs=input_var)\n",
    "    \n",
    "    def make_loss(yolo_pred, ae_pred):\n",
    "        w_yolo_loss, raw_yolo_loss, weight_decay_term, terms = make_yolo_loss(yolo_pred)\n",
    "        ae_loss = make_ae_loss(ae_pred)\n",
    "        \n",
    "        #just to make sure we don't compute this if we don't want to\n",
    "        if kwargs['lambda_ae'] == 0.:\n",
    "            loss = w_yolo_loss\n",
    "        else:\n",
    "            loss = w_yolo_loss + kwargs['lambda_ae'] * ae_loss\n",
    "        return loss, w_yolo_loss, ae_loss, raw_yolo_loss, weight_decay_term, terms\n",
    "    \n",
    "    def make_yolo_loss(pred):\n",
    "        yolo_loss, terms = get_detec_loss(pred, target_var, kwargs)\n",
    "        \n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(yolo, lasagne.regularization.l2)\n",
    "        weight_decay_term = kwargs['weight_decay'] * weightsl2\n",
    "        loss = yolo_loss + weight_decay_term\n",
    "        return loss, yolo_loss, weight_decay_term, terms\n",
    "    \n",
    "    def make_ae_loss(pred):\n",
    "        loss = squared_error(pred, input_var)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(ae, lasagne.regularization.l2)\n",
    "        loss += kwargs['weight_decay'] * weightsl2\n",
    "        return loss.mean()\n",
    "        \n",
    "    def make_train_fn():\n",
    "        '''takes as input the input, target vars and ouputs a loss'''\n",
    "        \n",
    "        loss, w_yolo_loss, ae_loss, raw_yolo_loss, weight_decay_term, terms =  make_loss(yolo_prediction, ae_prediction)\n",
    "        \n",
    "        term1,term2,term3,term4,term5 = terms\n",
    "        #only using params from yolo here -> because decoder has no new params -> tied weights\n",
    "        params = lasagne.layers.get_all_params(yolo, trainable=True) #+ lasagne.layers.get_all_params(ae, trainable=True)\n",
    "        updates = lasagne.updates.adam(loss, params,learning_rate=kwargs['learning_rate'])\n",
    "        if kwargs['lambda_ae'] != 0:\n",
    "            train_fn = theano.function([input_var, target_var], [loss,ae_loss,\n",
    "                                                                 w_yolo_loss, raw_yolo_loss,\n",
    "                                                                 weight_decay_term, term1,term2,\n",
    "                                                                 term3,term4,term5], \n",
    "                                                                 updates=updates)\n",
    "        else:\n",
    "            train_fn = theano.function([input_var, target_var], \n",
    "                                       [w_yolo_loss, raw_yolo_loss, weight_decay_term, term1,term2,term3,term4,term5],\n",
    "                                       updates=updates)\n",
    "        return train_fn\n",
    "        \n",
    "    \n",
    "    def make_test_or_val_fn():\n",
    "        '''takes as input the input, target vars and ouputs a non-dropout loss and an accuracy (intersection over union)'''\n",
    "        test_loss, w_yolo_loss, ae_loss, raw_yolo_loss, weight_decay_term, terms = make_loss(yolo_test_prediction,ae_test_prediction)\n",
    "        term1,term2,term3,term4,term5 = terms\n",
    "        if kwargs['lambda_ae'] != 0:\n",
    "            val_fn = theano.function([input_var, target_var], [test_loss,ae_loss,\n",
    "                                                                 w_yolo_loss, raw_yolo_loss,\n",
    "                                                                 weight_decay_term, term1,term2,\n",
    "                                                                 term3,term4,term5])\n",
    "        else:\n",
    "            val_fn = theano.function([input_var, target_var], [w_yolo_loss, raw_yolo_loss, \n",
    "                                                               weight_decay_term, term1,term2,term3,term4,term5])\n",
    "        return val_fn\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    def make_yolo_pred_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted grid'''\n",
    "        pred_fn = theano.function([input_var], yolo_test_prediction)\n",
    "        return pred_fn\n",
    "    \n",
    "    def make_ae_pred_fn():\n",
    "        pred_fn = theano.function([input_var], ae_test_prediction)\n",
    "        return pred_fn\n",
    "        \n",
    "    def make_box_fn():\n",
    "        pred_fn = make_yolo_pred_fn()\n",
    "        def box_fn(x, y, num_classes=kwargs['num_classes']):\n",
    "            y_tensor = y\n",
    "            pred_tensor = pred_fn(x)\n",
    "            pred_boxes, gt_boxes = get_all_boxes(pred_tensor=pred_tensor, \n",
    "                                                 y_tensor=y_tensor, \n",
    "                                                 num_classes=num_classes, conf_thresh=kwargs[\"conf_thresh\"])\n",
    "            return pred_boxes, gt_boxes\n",
    "        return box_fn\n",
    "            \n",
    "    def make_map_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted and the ground truth boxes)'''\n",
    "        pred_fn = make_yolo_pred_fn()\n",
    "        def MAP_fn(inp, gt, conf_thresh=0.7, iou_thresh=0.5,num_classes=4):\n",
    "            pred = pred_fn(inp)\n",
    "            MAP, tp, n, MAR = get_MAP(pred,gt, conf_thresh,iou_thresh, num_classes)\n",
    "            return MAP, tp, n, MAR\n",
    "    \n",
    "        return MAP_fn\n",
    "    \n",
    "    train_fn = make_train_fn()\n",
    "    test_or_val_fn = make_test_or_val_fn()\n",
    "    MAP_fn = make_map_fn()\n",
    "    yolo_pred_fn = make_yolo_pred_fn()\n",
    "    ae_pred_fn = make_ae_pred_fn()\n",
    "    box_fn = make_box_fn()\n",
    "    \n",
    "    return {\"tr\":train_fn, \"val\":test_or_val_fn, \"MAP\": MAP_fn, \"rec\": ae_pred_fn, \"box\": box_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FeaturePoolLayer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128 / 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
