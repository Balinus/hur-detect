{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import Conv2DLayer as conv\n",
    "from lasagne.layers import MaxPool2DLayer as maxpool\n",
    "from lasagne.layers import dropout\n",
    "from lasagne.layers import DenseLayer as fully_connected\n",
    "from lasagne.nonlinearities import rectify as relu\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "import sys\n",
    "import numpy as np\n",
    "#enable importing of notebooks\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "import inspect\n",
    "from helper_fxns import get_best_box, get_detec_loss, get_iou, make_test_data, get_detec_acc, get_final_box\n",
    "if __name__ == \"__main__\":\n",
    "    from data_loader import load_classification_dataset, load_detection_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hyperparams(frame):\n",
    "    args, _, _, values = inspect.getargvalues(frame)\n",
    "    #return dict(zip(args,values))\n",
    "    #del values['frame']\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_network(mode='detection', network_kwargs={}, detec_specific_kwargs={},\n",
    "                  pretrained_class_network=None, classif_weight_load_path=None, detect_weight_load_path=None):\n",
    "        \n",
    "    '''just classification'''\n",
    "    if mode=='classification':\n",
    "        pass\n",
    "        #train_fn, val_fn, input_var, network = build_classif_network(**network_kwargs)\n",
    "        \n",
    "   \n",
    "    elif mode == 'detection':\n",
    "        '''detection with an in-memory classification network'''\n",
    "        if pretrained_class_network:\n",
    "            train_fn,val_fn, box_fn, network, hyperparams = build_det_network(inmem_class_network,\n",
    "                                                                              input_var,\n",
    "                                                                              **network_kwargs)\n",
    "        elif classif_weight_load_path:\n",
    "            _,_,input_var,class_network = build_classif_network(load=True, load_path=classif_weight_load_path, \n",
    "                                                                **network_kwargs)\n",
    "            network_kwargs.update(detec_specific_kwargs)\n",
    "            train_fn,val_fn, box_fn, network,hyperparams = build_det_network(class_network,\n",
    "                                                                             input_var, \n",
    "                                                                             **network_kwargs)\n",
    "        elif detect_weight_load_path:\n",
    "            network_kwargs.update(detec_specific_kwargs)\n",
    "            train_fn,\n",
    "            val_fn, \n",
    "            box_fn, \n",
    "            network, \n",
    "            hyperparams = build_det_network(class_network,input_var,load_path=detect_weight_load_path,**network_kwargs)\n",
    "\n",
    "        else:\n",
    "            print \"running on non pretrained classif network!\"\n",
    "            train_fn,val_fn,input_var,class_network = build_classif_network(**network_kwargs)\n",
    "            \n",
    "            network_kwargs.update(detec_specific_kwargs)\n",
    "            train_fn,val_fn,box_fn, network, hyperparams = build_det_network(class_network,\n",
    "                                                                             input_var, \n",
    "                                                                             **network_kwargs)\n",
    "        \n",
    "        return train_fn, val_fn, box_fn, network, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_det_layers(class_net,\n",
    "                                  num_filters,\n",
    "                                  num_fc_units,\n",
    "                                  num_extra_conv, \n",
    "                                  nonlinearity,\n",
    "                                  n_boxes,\n",
    "                                  nclass,\n",
    "                                  grid_size,\n",
    "                                  w_init,\n",
    "                                  dropout_p):\n",
    "    \n",
    "    '''Takes a pretrained classification net and adds a few convolutional layers on top of it'''\n",
    "    \n",
    "    #define some syntatic sugar\n",
    "    conv_kwargs = dict(num_filters=num_filters, filter_size=(3,3), pad=1, nonlinearity=nonlinearity, W=w_init)\n",
    "    \n",
    "    #remove the fc, softmax, avg pooling layers from the classification network\n",
    "    class_net = strip_off_classif_fc_layers(class_net)\n",
    "\n",
    "        \n",
    "    #num_filters x 96 / (2^num_pool) x 96 / (2^num_pool)\n",
    "    network = conv(class_net, **conv_kwargs)\n",
    "    \n",
    "    \n",
    "    #shape: num_filters x 96 / (2^num_pool) x 96 / (2^num_pool)\n",
    "    for i in range(num_extra_conv):\n",
    "        network = conv(network, **conv_kwargs) \n",
    "        \n",
    "    \n",
    "    network = dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fully_connected(network, num_units=num_fc_units, nonlinearity=nonlinearity)  #shape: num_fc_units\n",
    "    network = dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fully_connected(network, num_units=(grid_size * grid_size) * (n_boxes* 5 + nclass),\n",
    "                                    nonlinearity=lasagne.nonlinearities.rectify)  \n",
    "                                    #shape: (grid_size * grid_size) * (n_boxes* 5 + nclass)     \n",
    "    network = lasagne.layers.ReshapeLayer(network, shape=([0],grid_size, grid_size,(n_boxes* 5 + nclass)))\n",
    "                                    #shape: grid_size, grid_size,(n_boxes* 5 + nclass))\n",
    "    \n",
    "    return network\n",
    "    \n",
    "\n",
    "def strip_off_classif_fc_layers(class_net):\n",
    "    while class_net.name != 'avg_pool_layer':\n",
    "        #keep cutting off layers until you get to the avg pool layer\n",
    "        class_net = class_net.input_layer\n",
    "    #then cut off the avg pool later\n",
    "    class_net = class_net.input_layer\n",
    "    return class_net\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_det_network(class_net, input_var,\n",
    "                      delta=0.00001,\n",
    "                      num_filters=512,\n",
    "                      num_fc_units=1024,\n",
    "                      num_extra_conv=1, \n",
    "                      nonlinearity=lasagne.nonlinearities.LeakyRectify(0.1),\n",
    "                     \n",
    "                      w_init=lasagne.init.HeUniform(),\n",
    "                      dropout_p=0.5,\n",
    "\n",
    "                      learning_rate = 0.001,\n",
    "                      weight_decay = 0.0005,\n",
    "                      momentum = 0.9,\n",
    "                      lc = 5, #penalty for getting coordinates wrong\n",
    "                      ln = 0.5, #penalty for guessing object when there isnt one\n",
    "                      n_boxes=1,\n",
    "                      nclass=1,\n",
    "                      grid_size=6,\n",
    "                      load=False,\n",
    "                      load_path=None):\n",
    "    \n",
    "    '''Takes a pretrained classification net and adds a few convolutional layers on top of it\n",
    "    and defines a detection loss function'''\n",
    "    '''Args:\n",
    "                      delta: smoothing constant to loss function (ie sqrt(x + delta)) \n",
    "                            -> if x is 0 gradient is undefined\n",
    "                      num_filters\n",
    "                      num_fc_units\n",
    "                      num_extra_conv: conv layers to add on to classification network \n",
    "                      nonlinearity: which nonlinearity to use throughout\n",
    "                      n_boxes: how many boxes should be predicted at each grid point,\n",
    "                      nclass: how many classes are we predicting,\n",
    "                      grid_size: size of the grid that encodes various \n",
    "                                locations of image (ie in the YOLO paper they use 7x7 grid)\n",
    "                      w_init: weight intitialization\n",
    "                      dropout_p: prob of dropping unit\n",
    "                      lc : penalty in YOLO loss function for getting coordinates wrong\n",
    "                      ln: penalty in YOLO loss for guessing object when there isn't one\n",
    "                      learning_rate\n",
    "                      weight_decay\n",
    "                      momentum\n",
    "                      load: whether to load weights or not\n",
    "                      load_path: path for loading weights'''\n",
    "\n",
    "    hyperparams = get_hyperparams(inspect.currentframe())\n",
    "    \n",
    "    #define target_var\n",
    "    det_target_var = T.tensor4('det_target_var') #is of shape (grid_size, grid_size,(n_boxes* 5 + nclass)\n",
    "    \n",
    "    print \"Building model and compiling functions...\" \n",
    "    \n",
    "    #make layers\n",
    "    network = build_det_layers(class_net,\n",
    "                                  num_filters,\n",
    "                                  num_fc_units,\n",
    "                                  num_extra_conv, \n",
    "                                  nonlinearity,\n",
    "                                  n_boxes,\n",
    "                                  nclass,\n",
    "                                  grid_size,\n",
    "                                  w_init,\n",
    "                                  dropout_p)\n",
    "    \n",
    "    #load in any pretrained weights\n",
    "    if load:\n",
    "        network = load_weights(load_path, network)\n",
    "    \n",
    "    #compile theano functions\n",
    "    train_fn, val_fn, box_fn = make_fns(network,input_var, det_target_var, lc, ln,\n",
    "                                        learning_rate, momentum, weight_decay, delta)\n",
    "    \n",
    "    return train_fn, val_fn, box_fn, network, hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-42-3f4daaf3a6d5>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-3f4daaf3a6d5>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    with np.load(file_path) as f:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "def load_weights(file_path, network):\n",
    "    '''grabs weights from an npz file'''\n",
    "    with np.load(file_path) as f:\n",
    "        param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "        lasagne.layers.set_all_param_values(network, param_values)\n",
    "    return network\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_fns(network,input_var, det_target_var, lc, ln, learning_rate, momentum, weight_decay, delta):\n",
    "    '''Compiles theano train, test, box_fns'''\n",
    "    #deterministic determines whether to use dropout or not in forward pass\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    prediction = lasagne.layers.get_output(network, deterministic=False)\n",
    "    \n",
    "    \n",
    "    def make_loss(pred):\n",
    "        loss = get_detec_loss(pred, det_target_var, lc, ln, delta)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "        loss += weight_decay * weightsl2\n",
    "        return loss\n",
    "    \n",
    "    def make_train_fn():\n",
    "        '''takes as input the input, target vars and ouputs a loss'''\n",
    "        \n",
    "        loss =  make_loss(prediction)\n",
    "        weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "        params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "        updates = lasagne.updates.nesterov_momentum(loss, \n",
    "                                                    params, \n",
    "                                                    learning_rate=learning_rate, \n",
    "                                                    momentum=momentum)\n",
    "        train_fn = theano.function([input_var, det_target_var], loss, updates=updates)\n",
    "        return train_fn\n",
    "        \n",
    "    \n",
    "    def make_test_or_val_fn():\n",
    "        '''takes as input the input, target vars and ouputs a non-dropout loss and an accuracy (intersection over union)'''\n",
    "        test_loss = make_loss(test_prediction)\n",
    "        test_acc = get_detec_acc(test_prediction, det_target_var)\n",
    "        val_fn = theano.function([input_var, det_target_var], [test_loss, test_acc])\n",
    "        return val_fn\n",
    "    \n",
    "    \n",
    "    def make_box_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted and the ground truth boxes)'''\n",
    "        pred_boxes = get_final_box(test_prediction)\n",
    "        gt_boxes = get_final_box(det_target_var)\n",
    "        box_fn = theano.function([input_var, det_target_var], [pred_boxes, gt_boxes])\n",
    "        return box_fn\n",
    "    \n",
    "    def make_pred_fn():\n",
    "        '''takes as input the input, target vars and outputs the predicted grid'''\n",
    "        pred_fn = theano.function([input_var], test_prediction)\n",
    "        return pred_fn\n",
    "        \n",
    "        \n",
    "    train_fn = make_train_fn()\n",
    "    test_or_val_fn = make_test_or_val_fn()\n",
    "    box_fn = make_box_fn()\n",
    "    pred_fn = make_pred_fn()\n",
    "    \n",
    "    return train_fn, test_or_val_fn, box_fn #,pred_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_classif_layers(input_var,\n",
    "                      input_shape,\n",
    "                      num_filters,\n",
    "                      num_fc_units,\n",
    "                      num_extra_conv, \n",
    "                      num_pool,\n",
    "                      nonlinearity,\n",
    "                      w_init,\n",
    "                      dropout_p):\n",
    "    \n",
    "    '''builds architecture for classification'''\n",
    "    \n",
    "    conv_kwargs = dict(num_filters=num_filters, filter_size=(3,3), pad=1,nonlinearity=nonlinearity, W=w_init)\n",
    "    \n",
    "    ''' 8x8x96'''\n",
    "    network = lasagne.layers.InputLayer(shape=input_shape, input_var=input_var)\n",
    "    \n",
    "    '''num_filters x 96 x 96 '''\n",
    "    network = conv(network, **conv_kwargs)\n",
    "    \n",
    "    for i in range(num_pool):\n",
    "\n",
    "        '''num_filters x 96 / (2^i) x 96 / (2^i)'''\n",
    "        network = maxpool(network, pool_size=(2,2))\n",
    "\n",
    "        '''num_filters x 96 / (2^i) x 96 / (2^i)'''\n",
    "        network = conv(network,**conv_kwargs )\n",
    "        \n",
    "        for j in range(num_extra_conv):\n",
    "            \n",
    "            '''num_filters x 96 / (2^i) x 96 / (2^i)'''\n",
    "            network = conv(network,**conv_kwargs)\n",
    "\n",
    "\n",
    "    \n",
    "    '''shape: num_filters x 96 / (2^num_pool) x 96 / (2^num_pool)'''\n",
    "   \n",
    "    #average pooling\n",
    "    \n",
    "    '''name this layer, so we know where it is when we cut layers off this network'''\n",
    "    network = lasagne.layers.Pool2DLayer(network, pool_size=(2,2), mode='average_exc_pad', name='avg_pool_layer')\n",
    "    \n",
    "    network = dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fully_connected(network,num_units=num_fc_units, nonlinearity=relu) #shape: num_fc_units\n",
    "    \n",
    "    network = dropout(network, p=dropout_p) #shape: same as above\n",
    "    network = fully_connected(network, num_units=2, nonlinearity=lasagne.nonlinearities.softmax) #shape: 2 (2 classes)\n",
    "    \n",
    "    return network\n",
    "\n",
    "def build_classif_network(learning_rate = 0.01,\n",
    "                  momentum = 0.9,\n",
    "                  num_filters=128,\n",
    "                  num_fc_units=1024,\n",
    "                  num_extra_conv=0, \n",
    "                  num_pool=3,\n",
    "                  nonlinearity=lasagne.nonlinearities.LeakyRectify(0.1),\n",
    "                  w_init=lasagne.init.HeUniform(),\n",
    "                  dropout_p=0.5,\n",
    "                  weight_decay=0.0005,\n",
    "                  load=False,\n",
    "                  load_path='model.npz',\n",
    "                  input_shape=(None,8,96,96)):\n",
    "    \n",
    "    ''' builds network for classification, which is pretrained on a classification task\n",
    "        (ie: first we put in images and have the network guess if its a hurricane or not be fire diubgf)'''\n",
    "    '''Args:\n",
    "                  learning_rate\n",
    "                  momentum\n",
    "                  num_filters: number of convolutional filters\n",
    "                  num_fc_units: number of units out of fc layer\n",
    "                  num_extra_conv: number of additional conv layers before avg pooling and fc\n",
    "                  num_pool: number of max pool layers (determines number of matching conv layers as well)\n",
    "                  nonlinearity=lasagne.nonlinearities.LeakyRectify(0.1)\n",
    "                  w_init: weight intialization strategy\n",
    "                  dropout_p: probabiltiy of setting units to zero in dropout scheme\n",
    "                  weight_decay: coefficient to L2 norm weight penalty\n",
    "                  load: whether to load weights\n",
    "                  load_path: path of where file of weights is\n",
    "                  input_shape: input image dimensions\n",
    "                  '''\n",
    "    \n",
    "    \n",
    "    input_var = T.tensor4('input_var')\n",
    "    classif_target_var = T.ivector('classif_target_var')\n",
    "    \n",
    "    print(\"Building model and compiling functions...\")\n",
    "    \n",
    "    \n",
    "    '''get actual architecture'''\n",
    "    network = build_classif_layers(input_var,\n",
    "                                            input_shape,\n",
    "                                            num_filters,\n",
    "                                            num_fc_units,\n",
    "                                            num_extra_conv, \n",
    "                                            num_pool,\n",
    "                                            nonlinearity,\n",
    "                                            w_init,\n",
    "                                            dropout_p)\n",
    "    \n",
    "    '''load weights if necessary'''\n",
    "    if load:\n",
    "        with np.load(load_path) as f:\n",
    "            param_values = [f['arr_%d' % i] for i in range(len(f.files))]\n",
    "            lasagne.layers.set_all_param_values(network, param_values)\n",
    "\n",
    "    \n",
    "    '''calculate loss -> standard cross entropy with weight decay'''\n",
    "    prediction = lasagne.layers.get_output(network, deterministic=False)\n",
    "    loss = lasagne.objectives.categorical_crossentropy(prediction, classif_target_var)\n",
    "    loss = loss.mean()\n",
    "    weightsl2 = lasagne.regularization.regularize_network_params(network, lasagne.regularization.l2)\n",
    "    loss += weight_decay * weightsl2\n",
    "    \n",
    "    \n",
    "    '''calculate test loss (cross entropy with no regularization) and accuracy'''\n",
    "    test_prediction = lasagne.layers.get_output(network, deterministic=True)\n",
    "    test_loss = lasagne.objectives.categorical_crossentropy(test_prediction,\n",
    "                                                                classif_target_var)\n",
    "    test_loss = test_loss.mean()\n",
    "    test_acc = T.mean(T.eq(T.argmax(test_prediction, axis=1), classif_target_var),\n",
    "                          dtype=theano.config.floatX)\n",
    "\n",
    "    '''calculate updates -> nesterov momentum sgd'''\n",
    "    params = lasagne.layers.get_all_params(network, trainable=True)\n",
    "    updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=learning_rate, momentum=momentum)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    '''train_fn -> takes in input,label pairs -> outputs loss '''\n",
    "    train_fn = theano.function([input_var, classif_target_var], loss, updates=updates)\n",
    "\n",
    "\n",
    "    '''val_fn -> takes in input,label pairs -> outputs non regularized loss and accuracy '''\n",
    "    val_fn = theano.function([input_var, classif_target_var], [test_loss, test_acc])\n",
    "\n",
    "    return train_fn, val_fn, input_var, network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on non pretrained classif network!\n",
      "Building model and compiling functions...\n",
      "Building model and compiling functions...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<theano.compile.function_module.Function at 0x7f3f29b004d0>,\n",
       " <theano.compile.function_module.Function at 0x7f3f1e483cd0>,\n",
       " <theano.compile.function_module.Function at 0x7f3f1dcdb810>,\n",
       " <lasagne.layers.shape.ReshapeLayer at 0x7f3f2b869890>,\n",
       " {'class_net': <lasagne.layers.dense.DenseLayer at 0x7f3f30b19e50>,\n",
       "  'delta': 1e-05,\n",
       "  'dropout_p': 0.5,\n",
       "  'grid_size': 6,\n",
       "  'input_var': input_var,\n",
       "  'lc': 5,\n",
       "  'learning_rate': 0.001,\n",
       "  'ln': 0.5,\n",
       "  'load': False,\n",
       "  'load_path': None,\n",
       "  'momentum': 0.9,\n",
       "  'n_boxes': 1,\n",
       "  'nclass': 1,\n",
       "  'nonlinearity': <lasagne.nonlinearities.LeakyRectify at 0x7f3f30b4e1d0>,\n",
       "  'num_extra_conv': 1,\n",
       "  'num_fc_units': 1024,\n",
       "  'num_filters': 512,\n",
       "  'w_init': <lasagne.init.HeUniform at 0x7f3f30b4e210>,\n",
       "  'weight_decay': 0.0005})"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    build_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
