{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "__author__ = 'racah'\n",
    "import h5py\n",
    "import numpy as np\n",
    "from operator import mul\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "# from print_n_plot import plot_ims_with_boxes\n",
    "%matplotlib inline\n",
    "\n",
    "#1 is hur\n",
    "#0 is nhur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_precomputed_data(paths=[\"/global/project/projectdirs/dasrepo/gordon_bell/climate/data/detection/theano_data/theano_hur_train.h5\",\n",
    "                                \"/global/project/projectdirs/dasrepo/gordon_bell/climate/data/detection/theano_data/theano_hur_val.h5\" ],\n",
    "                             out_of_core=True):\n",
    "    #Can't slice the data here b/c slicing an h5py file object will read it into memory and we \n",
    "    #want to do out of core\n",
    "    data = []\n",
    "    for path in paths:\n",
    "        h5o = h5py.File(path)\n",
    "        x,y = h5o['data'], h5o['label']\n",
    "        if not out_of_core:\n",
    "            x,y = x[:], y[:]\n",
    "        data.extend([x,y])\n",
    "    return data\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "def load_data(path='/project/projectdirs/dasrepo/gordon_bell/climate/data/detection/hur_train_val.h5',\n",
    "              num_ims=-1,use_negative=False, scale_factor=16, just_test=False, use_boxes=False, seed=4, caffe_format=False):\n",
    "    \n",
    "    \n",
    "    inputs, boxes, labels = load_hurricanes(path, num_ims, use_negative)\n",
    "    \n",
    "    xy_dims = np.asarray(inputs.shape[2:])\n",
    "    d_labels = create_detection_gr_truth(xy_dims, scale_factor, boxes, caffe_format=caffe_format)\n",
    "    if just_test:\n",
    "        ret = [inputs, d_labels] if not use_boxes else [inputs, d_labels, boxes]\n",
    "        return ret\n",
    "    else:\n",
    "        if use_boxes:\n",
    "            x_tr, y_tr, box_tr, x_val, y_val, box_val = set_up_train_test_val(inputs, d_labels, seed=seed, boxes=boxes)\n",
    "            return x_tr, y_tr, box_tr, x_val, y_val, box_val\n",
    "            \n",
    "        else: \n",
    "            x_tr, y_tr, x_val, y_val = set_up_train_test_val(inputs, d_labels,seed=seed)\n",
    "            return x_tr, y_tr, x_val, y_val\n",
    "\n",
    "\n",
    "def load_hurricanes(path,num_ims=-1, use_negative=False):\n",
    "\n",
    "    print 'getting data...'\n",
    "    h5f = h5py.File(path)\n",
    "    hshape = h5f['hurs'].shape[0]\n",
    "    if num_ims == -1:\n",
    "        excerpt = slice(0,hshape)\n",
    "    else:\n",
    "        excerpt = slice(0,num_ims)\n",
    "    if use_negative:\n",
    "        excerpt = slice(0,num_ims / 2)\n",
    "        nhurs = h5f['nhurs'][excerpt]\n",
    "\n",
    "    hurs = h5f['hurs'][excerpt]\n",
    "    hur_boxes = h5f['hur_boxes'][excerpt]\n",
    "\n",
    "    hurs_bboxes = np.asarray(hur_boxes).reshape(hurs.shape[0],4)\n",
    "\n",
    "    \n",
    "    #convert from xmin,ymin,xmax,ymax to x_center, y_center, width, heights\n",
    "    hurs_bboxes = convert_bbox_minmax_to_cent_xywh(hurs_bboxes)\n",
    "\n",
    "    if use_negative:\n",
    "        nhurs_bboxes = np.zeros((nhurs.shape[0],4))\n",
    "        inputs = np.vstack((hurs,nhurs))\n",
    "        bboxes = np.vstack((hurs_bboxes,nhurs_bboxes))\n",
    "    else:\n",
    "        inputs = hurs\n",
    "        bboxes = hurs_bboxes\n",
    "\n",
    "    labels = np.zeros((inputs.shape[0]))\n",
    "    labels[:hurs.shape[0]] = 1\n",
    "    print inputs.shape[0]\n",
    "    \n",
    "    \n",
    "    return inputs, bboxes, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def convert_bbox_minmax_to_cent_xywh(bboxes):\n",
    "    #current bbox set up is xmin,ymin,xmax,ymax\n",
    "    xmin, ymin, xmax, ymax = [np.expand_dims(bboxes[:,i], axis=1) for i in range(4)]\n",
    "\n",
    "    w = xmax - xmin\n",
    "    h = ymax - ymin\n",
    "    x_c = xmin + w / 2.\n",
    "    y_c = ymin + h / 2.\n",
    "    new_bboxes = np.hstack((x_c, y_c, w, h))\n",
    "    return new_bboxes\n",
    "    \n",
    "    \n",
    "def get_train_val_test_ix(num_ims,seed):\n",
    "    # tr, te, val is 0.6,0.2,0.2\n",
    "    ix = range(num_ims)\n",
    "\n",
    "    n_val = int(0.2*num_ims)\n",
    "    n_tr =  num_ims - n_val\n",
    "\n",
    "    np.random.RandomState(seed).shuffle(ix)\n",
    "    val_i = ix[:n_val]\n",
    "    tr_i = ix[n_val:]\n",
    "\n",
    "    return tr_i,val_i\n",
    "\n",
    "\n",
    "def set_up_train_test_val(hurs, labels, seed, boxes=None):\n",
    "\n",
    "    tr_i, val_i = get_train_val_test_ix(hurs.shape[0], seed)\n",
    "    \n",
    "\n",
    "\n",
    "    x_tr, lbl_tr = hurs[tr_i], labels[tr_i]\n",
    "    \n",
    "    #normalize data\n",
    "    x_tr, tr_min, tr_max = normalize(x_tr)\n",
    "    \n",
    "    \n",
    "    # get test and val data and normazlize using statistics from train\n",
    "    x_val, lbl_val = hurs[val_i], labels[val_i]\n",
    "    x_val,_,_ = normalize(x_val, tr_min, tr_max)\n",
    "    \n",
    "    if type(boxes) != type(None):\n",
    "        box_tr = boxes[tr_i]\n",
    "        box_val = boxes[val_i]\n",
    "        return x_tr, lbl_tr, box_tr, x_val, lbl_val, box_val\n",
    "    else:\n",
    "        return x_tr, lbl_tr, x_val, lbl_val\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "# does standardize and normalize for any axis and will return statistics,\n",
    "#so you can fit and run on test and validation (both these features do not come together in sklearn)\n",
    "#otherwise sklearn.preprocessing would be the way to go\n",
    "def standardize(arr,mean=None,std=None, axis=(0,2,3)):\n",
    "    if mean is None or std is None:\n",
    "        mean = arr.mean(axis=axis)\n",
    "        std = arr.std(axis=axis)\n",
    "    arr -= mean\n",
    "    arr /= std\n",
    "    \n",
    "    return arr, mean, std\n",
    "        \n",
    "\n",
    "def normalize(arr,min_=None, max_=None, axis=(0,2,3)):\n",
    "        if min_ is None or max_ is None:\n",
    "            min_ = arr.min(axis=(0,2,3), keepdims=True)\n",
    "\n",
    "            max_ = arr.max(axis=(0,2,3), keepdims=True)\n",
    "\n",
    "        midrange = (max_ + min_) / 2.\n",
    "\n",
    "        range_ = max_ - min_\n",
    "\n",
    "        arr = (arr - midrange) / (range_ /2.)\n",
    "        return arr, min_, max_\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def create_detection_gr_truth(xy, scale_factor, bbox_array, caffe_format=False):\n",
    "    #x_xy : 1,2 tuple with x and y sizes for image\n",
    "    #scale_factor: factor to scale xy size by fro gr_truth grid for YOLO\n",
    "    #scale_factor = float(scale_factor)\n",
    "\n",
    "\n",
    "    #make sure xy coords divide cleanly with scale_factor\n",
    "    assert not np.any(xy % scale_factor), \"scale factor %i must divide the xy (%s) coords cleanly \" %(scale_factor, x_xy)\n",
    "    \n",
    "    \n",
    "    x_len,y_len = xy[0] / scale_factor, xy[1] / scale_factor\n",
    "    last_dim = 7 #x,y,w,h,c plus two binary number for phur or pnot for one hot encoding\n",
    "\n",
    "\n",
    "    #divide up bbox with has range 0-95 to 0-95/scale_factor (so 6x6 for scale factor of 16)\n",
    "    bb_scaled = bbox_array / scale_factor\n",
    "\n",
    "    #each coordinate goes at index i,j in the 6x6 array, where i,j are the coordinates of the\n",
    "    #lower left corner of the grid that center of the box (in 6x6 space ) falls on\n",
    "    inds = np.floor(bb_scaled[:,:2]).astype('int')\n",
    "\n",
    "    #xywh where x and y are offset from lower left corner of grid thay are in [0,1] and w and h\n",
    "    # are what fraction the width and height of bboxes are of the total width and total height of the image\n",
    "    xywh = np.copy(bb_scaled)\n",
    "\n",
    "    #subtract the floored values to get the offset from the grid cell\n",
    "    xywh[:,:2] -= inds[:,:2].astype('float')\n",
    "\n",
    "    #divide by scaled width and height to get wdith and height relative to width and height of image\n",
    "    xywh[:,2] /= x_len\n",
    "    xywh[:,3] /= y_len\n",
    "\n",
    "    #make gr_truth which is \n",
    "    if caffe_format:\n",
    "        gr_truth = np.zeros((bbox_array.shape[0],last_dim, x_len, y_len ))\n",
    "    else:\n",
    "        gr_truth = np.zeros((bbox_array.shape[0],x_len ,y_len, last_dim))\n",
    "\n",
    "    #sickens me to a do a for loop here, but numpy ain't cooperating\n",
    "    # I tried gr_truth[np.arange(gr_truth.shape[0]),inds[:0], inds[:1]][:,4] = xywh\n",
    "    #but it did not work\n",
    "\n",
    "    # we assume one box per image here\n",
    "    # for each grid point that is center of image plop in center, and width and height and class\n",
    "    for i in range(gr_truth.shape[0]):\n",
    "        if caffe_format:\n",
    "            #put coordinates\n",
    "            gr_truth[i, :4,inds[i,0], inds[i,1]] = xywh[i]\n",
    "\n",
    "            #put in confidence\n",
    "            gr_truth[i, 4, inds[i,0], inds[i,1]] = 1 if np.sum(xywh[i]) > 0. else 0.\n",
    "\n",
    "            #put in class label\n",
    "            gr_truth[i, 5, inds[i,0], inds[i,1]] = 1 if np.sum(xywh[i]) > 0. else 0.\n",
    "            \n",
    "            gr_truth[i,6, inds[i,0], inds[i,1]] = 0. if np.sum(xywh[i]) > 0. else 1.\n",
    "        \n",
    "        else:\n",
    "            #put coordinates\n",
    "            gr_truth[i,inds[i,0], inds[i,1], :4] = xywh[i]\n",
    "\n",
    "            #put in confidence\n",
    "            gr_truth[i,inds[i,0], inds[i,1], 4] = 1 if np.sum(xywh[i]) > 0. else 0.\n",
    "\n",
    "            #put in class label\n",
    "            gr_truth[i,inds[i,0], inds[i,1], 5] = 1. if np.sum(xywh[i]) > 0. else 0.\n",
    "\n",
    "            gr_truth[i,inds[i,0], inds[i,1], 6] = 0. if np.sum(xywh[i]) > 0. else 1.\n",
    "        \n",
    "\n",
    "    return gr_truth\n",
    "\n",
    "def test_grid(bbox, grid, orig_dim=96, scale_factor=16, caffe_format=False):\n",
    "    x,y = bbox[0] / scale_factor, bbox[1] / scale_factor\n",
    "    xo,yo = (bbox[0] % scale_factor) / float(scale_factor), (bbox[1] % scale_factor) / float(scale_factor)\n",
    "    w,h = bbox[2] / scale_factor / (orig_dim / scale_factor), bbox[3] / scale_factor/ (orig_dim / scale_factor)\n",
    "    \n",
    "    if caffe_format:\n",
    "        l_box = grid[:7,x,y]\n",
    "    else:\n",
    "        l_box = grid[x,y,:7]\n",
    "    real_box = np.array([xo,yo,w,h,1.,1., 0.])\n",
    "    print l_box\n",
    "    print real_box\n",
    "    assert np.allclose(l_box, real_box), \"Tests Failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting data...\n",
      "40\n",
      "[ 0.125       0.75        0.29166666  0.29166666  1.          1.          0.        ]\n",
      "[ 0.125       0.75        0.29166667  0.29166667  1.          1.          0.        ]\n",
      "[ 0.125       0.75        0.29166666  0.29166666  1.          1.          0.        ]\n",
      "[ 0.125       0.75        0.29166667  0.29166667  1.          1.          0.        ]\n",
      "[ 0.125       0.0625      0.29166666  0.29166666  1.          1.          0.        ]\n",
      "[ 0.125       0.0625      0.29166667  0.29166667  1.          1.          0.        ]\n",
      "[ 0.5         0.4375      0.29166666  0.29166666  1.          1.          0.        ]\n",
      "[ 0.5         0.4375      0.29166667  0.29166667  1.          1.          0.        ]\n",
      "[ 0.125       0.          0.29166666  0.29166666  1.          1.          0.        ]\n",
      "[ 0.125       0.          0.29166667  0.29166667  1.          1.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:246: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    xt,yt,bt,xv,yv,bv = load_data(num_ims=40, caffe_format=True, use_boxes=True)\n",
    "    for i in np.random.randint(0,xt.shape[0], size=(5)):\n",
    "        test_grid(bt[i], yt[i], caffe_format=True)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
