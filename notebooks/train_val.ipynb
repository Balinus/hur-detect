{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from helper_fxns.ipynb\n",
      "importing Jupyter notebook from data_loader.ipynb\n",
      "importing Jupyter notebook from build_network.ipynb\n",
      "importing Jupyter notebook from run_dir.ipynb\n",
      "importing Jupyter notebook from print_n_plot.ipynb\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "from helper_fxns import early_stop\n",
    "import logging\n",
    "from data_loader import load_precomputed_data\n",
    "from build_network import build_network\n",
    "from run_dir import create_run_dir\n",
    "from print_n_plot import print_train_results,plot_learn_curve,print_val_results, plot_ims_with_boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False, num_ims=-1):\n",
    "    if num_ims == -1:\n",
    "        end_ind = inputs.shape[0]\n",
    "    else:\n",
    "        end_ind = num_ims\n",
    "        \n",
    "    assert inputs.shape[0] == targets.shape[0], \"inputs and targets different sizes\"\n",
    "    if shuffle:\n",
    "        indices = np.arange(inputs.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "    if batchsize > end_ind:\n",
    "        batchsize = end_ind\n",
    "    for start_idx in range(0, end_ind - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[start_idx: start_idx + batchsize], targets[start_idx: start_idx + batchsize]\n",
    "\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "   \n",
    "    \n",
    "def train_one_epoch(x,y,batchsize, train_fn, val_fn, num_ims):\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(x, y, batchsize, shuffle=True, num_ims=num_ims):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        _, acc = val_fn(inputs, targets)\n",
    "        train_acc += acc\n",
    "        train_batches += 1\n",
    "    return train_err, train_acc, train_batches\n",
    "\n",
    "def val_one_epoch(x, y, batchsize, val_fn, num_ims):\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(x,y, batchsize, shuffle=False, num_ims=num_ims):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        return val_err, val_acc, val_batches\n",
    "def do_one_epoch(epoch,num_epochs, x_train, y_train, x_val, y_val, batchsize, train_fn, val_fn,\n",
    "                 train_errs, train_accs, val_errs, val_accs, val_counter, logger, num_ims):\n",
    "        start_time = time.time()\n",
    "        tr_err, tr_acc, tr_batches = train_one_epoch(x_train, y_train,\n",
    "                                                     batchsize=batchsize,\n",
    "                                                     train_fn=train_fn,\n",
    "                                                     val_fn=val_fn, num_ims=num_ims)\n",
    "                \n",
    "        train_errs.append(tr_err / tr_batches)\n",
    "        train_accs.append(tr_acc / tr_batches)\n",
    "        print_train_results(epoch, num_epochs, start_time, tr_err / tr_batches, tr_acc / tr_batches, logger)\n",
    "        \n",
    "        \n",
    "        if epoch % 50 == 0:\n",
    "            val_err, val_acc, val_batches = val_one_epoch(x_val, y_val,\n",
    "                                                         batchsize=batchsize,\n",
    "                                                          val_fn=val_fn, num_ims=num_ims)\n",
    "\n",
    "            val_counter.append(epoch)\n",
    "            val_errs.append(val_err / val_batches)\n",
    "            val_accs.append(val_acc / val_batches)\n",
    "            print_val_results(val_err, val_acc / val_batches, logger)\n",
    "        \n",
    "\n",
    "def setup_logging(save_path):\n",
    "    logger = logging.getLogger('simple_example')\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    # create file handler which logs even debug messages\n",
    "    fh = logging.FileHandler('%s/training.log'%(save_path))\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    # create console handler with a higher log level\n",
    "    ch = logging.StreamHandler()\n",
    "    ch.setLevel(logging.DEBUG)\n",
    "    logger.addHandler(ch)\n",
    "    logger.addHandler(fh)\n",
    "    return logger\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(datasets, network,\n",
    "          fns, \n",
    "          num_epochs, \n",
    "          num_ims=-1,\n",
    "          save_weights=False, \n",
    "          save_plots=True, \n",
    "          save_path='./results', \n",
    "          batchsize=128, \n",
    "          load_path=None):\n",
    "    \n",
    "    \n",
    "    logger = setup_logging(save_path)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    train_fn, val_fn, box_fn = fns\n",
    "\n",
    "        \n",
    "    #todo add in detect\n",
    "    x_tr, y_tr,x_val, y_val = datasets\n",
    "    \n",
    "    if batchsize is None or x_tr.shape[0] < batchsize:\n",
    "        batchsize = x_tr.shape[0]\n",
    "    \n",
    "    \n",
    "    #pick 6 random images to look at\n",
    "    inds = np.random.randint(low=0, high=x_tr.shape[0], size=(6,))\n",
    "    \n",
    "    print \"Starting training...\" \n",
    "    train_errs, train_accs, val_errs, val_accs, val_counter = [], [], [], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        do_one_epoch(epoch,num_epochs, x_tr, y_tr, x_val, y_val,batchsize, train_fn, val_fn,\n",
    "                     train_errs, train_accs, val_errs, val_accs,val_counter, logger, num_ims)\n",
    "        \n",
    "\n",
    "        \n",
    "        if epoch % 10 == 0 and epoch != 0:\n",
    "            plot_learn_curve(train_errs,val_errs,val_counter, 'err', save_plots=save_plots,path=save_path)\n",
    "            plot_learn_curve(train_accs,val_accs,val_counter, 'acc', save_plots=save_plots, path=save_path)\n",
    "\n",
    "            if epoch % 100 == 0 or epoch < 100:\n",
    "                pred_boxes, gt_boxes = box_fn(x_tr,y_tr)              \n",
    "                plot_ims_with_boxes(x_tr[inds], pred_boxes[inds], gt_boxes[inds], epoch=epoch,\n",
    "                                    save_plots=save_plots, path=save_path)\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "        if save_weights and epoch % 10 == 0:\n",
    "  \n",
    "            np.savez('%s/model.npz'%(save_path), *lasagne.layers.get_all_param_values(network))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model and compiling functions...\n",
      "<class 'h5py._hl.dataset.Dataset'> <class 'h5py._hl.dataset.Dataset'>\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "<type 'numpy.ndarray'> (128, 8, 96, 96) <type 'numpy.ndarray'> (128, 6, 6, 6)\n",
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 of 3 took 12.724s\n",
      "Epoch 1 of 3 took 12.724s\n",
      "\ttraining los:\t\t10.9611\n",
      "\ttraining los:\t\t10.9611\n",
      "\ttraining acc:\t\t0.0631 %\n",
      "\ttraining acc:\t\t0.0631 %\n",
      "  validation loss:\t\t68.255062\n",
      "  validation loss:\t\t68.255062\n",
      "  validation accuracy:\t\t0.10 %\n",
      "  validation accuracy:\t\t0.10 %\n",
      "Epoch 2 of 3 took 12.695s\n",
      "Epoch 2 of 3 took 12.695s\n",
      "\ttraining los:\t\t9.5021\n",
      "\ttraining los:\t\t9.5021\n",
      "\ttraining acc:\t\t0.8707 %\n",
      "\ttraining acc:\t\t0.8707 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3f952c005180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m           \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m           load_path=None)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-57a2abec2f67>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(datasets, network, fns, num_epochs, num_ims, save_weights, save_plots, save_path, batchsize, load_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         do_one_epoch(epoch,num_epochs, x_tr, y_tr, x_val, y_val,batchsize, train_fn, val_fn,\n\u001b[0;32m---> 34\u001b[0;31m                      train_errs, train_accs, val_errs, val_accs,val_counter, logger, num_ims)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e3bb914a78bf>\u001b[0m in \u001b[0;36mdo_one_epoch\u001b[0;34m(epoch, num_epochs, x_train, y_train, x_val, y_val, batchsize, train_fn, val_fn, train_errs, train_accs, val_errs, val_accs, val_counter, logger, num_ims)\u001b[0m\n\u001b[1;32m     31\u001b[0m                                                   \u001b[0mbatchsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                                   \u001b[0mtrain_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                                                   val_fn=val_fn, num_ims=num_ims)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m      \u001b[0mtrain_errs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_err\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtr_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-e3bb914a78bf>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(x, y, batchsize, train_fn, val_fn, num_ims)\u001b[0m\n\u001b[1;32m      8\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterate_minibatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_ims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_ims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m      \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m      \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m      \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m      \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/global/common/cori/software/python/2.7-anaconda/envs/deeplearning/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'position_of_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__==\"__main__\":\n",
    "    run_dir = create_run_dir()\n",
    "    xt,yt,xv,yv = load_precomputed_data()\n",
    "    train_fn, val_fn, box_fn, network, hyperparams = build_network(**{'num_filters': 10, 'num_fc_units': 10, 'num_extra_conv': 0})\n",
    "    print type(xt), type(yt)\n",
    "    for a,b in iterate_minibatches(xt, yt, 128, shuffle=False, num_ims=1000):\n",
    "        print type(a), a.shape, type(b), b.shape\n",
    "    train((xt,yt,xv,yv), network,\n",
    "          fns=(train_fn, val_fn, box_fn), \n",
    "          num_epochs=3, \n",
    "          num_ims=1000,\n",
    "          save_weights=False, \n",
    "          save_plots=True, \n",
    "          save_path=run_dir, \n",
    "          batchsize=128, \n",
    "          load_path=None)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
