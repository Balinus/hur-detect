{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from nbfinder import NotebookFinder\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "\n",
    "import netCDF4 as nc\n",
    "from netCDF4 import MFDataset\n",
    "from os import listdir, system\n",
    "from os.path import isfile, join, isdir\n",
    "import numpy as np\n",
    "import imp\n",
    "import itertools\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import inspect\n",
    "import copy\n",
    "from util import get_camfiles,convert_nc_data_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataSet(object):\n",
    "\n",
    "    def __init__(self,\n",
    "               images,\n",
    "               labels,\n",
    "               dtype=dtypes.float32):\n",
    "\n",
    "\n",
    "        self._images = images\n",
    "        self._labels = labels\n",
    "        self._epochs_completed = 0\n",
    "        self._index_in_epoch = 0\n",
    "\n",
    "    @property\n",
    "    def images(self):\n",
    "        return self._images\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        return self._labels\n",
    "\n",
    "    @property\n",
    "    def num_examples(self):\n",
    "        return self._num_examples\n",
    "\n",
    "    @property\n",
    "    def epochs_completed(self):\n",
    "        return self._epochs_completed\n",
    "    \n",
    "    def shuffle(self):\n",
    "        pass\n",
    "\n",
    "    def next_batch(self, batch_size, shuffle=True):\n",
    "        \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "        start = self._index_in_epoch\n",
    "        # Shuffle for the first epoch\n",
    "        if self._epochs_completed == 0 and start == 0 and shuffle:\n",
    "            perm0 = np.arange(self._num_examples)\n",
    "            np.random.shuffle(perm0)\n",
    "            \n",
    "            #shuffle files\n",
    "            seed = np.random.randint()\n",
    "            self._images.shuffle(seed)\n",
    "            #todo: same for labels\n",
    "            self._labels = self.labels[perm0]\n",
    "\n",
    "        # Go to the next epoch\n",
    "        if start + batch_size > self._num_examples:\n",
    "            # Finished epoch\n",
    "            self._epochs_completed += 1\n",
    "            # Get the rest examples in this epoch\n",
    "            rest_num_examples = self._num_examples - start\n",
    "            images_rest_part = self._images[start:self._num_examples]\n",
    "            labels_rest_part = self._labels[start:self._num_examples]\n",
    "            # Shuffle the data\n",
    "            if shuffle:\n",
    "                perm = np.arange(self._num_examples)\n",
    "                np.random.shuffle(perm)\n",
    "                self._images = self.images[perm]\n",
    "                self._labels = self.labels[perm]\n",
    "            # Start next epoch\n",
    "            start = 0\n",
    "            self._index_in_epoch = batch_size - rest_num_examples\n",
    "            end = self._index_in_epoch\n",
    "            images_new_part = self._images[start:end]\n",
    "            labels_new_part = self._labels[start:end]\n",
    "            return np.concatenate((images_rest_part, images_new_part), axis=0), np.concatenate((labels_rest_part, labels_new_part), axis=0)\n",
    "        else:\n",
    "            self._index_in_epoch += batch_size\n",
    "            end = self._index_in_epoch\n",
    "            return self._images[start:end], self._labels[start:end]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ClimateImage(object):\n",
    "    def __init__(self,filepaths, variables=[\"TMQ\", \"VBOT\", \"PSL\"],\n",
    "                 time_step_sample_freq=2, time_steps_per_example=1,time_steps_per_file=8):\n",
    "        \n",
    "\n",
    "        frame = inspect.currentframe()\n",
    "        # set self.k = v for every k,v pair in __init__ except self of course\n",
    "        self.set_constructor_args(frame)\n",
    "        \n",
    "        self.num_files = len(self.filepaths)\n",
    "        self.examples_per_file = (time_steps_per_file / time_step_sample_freq) / time_steps_per_example\n",
    "        self.total_examples = self.num_files * self.examples_per_file\n",
    "\n",
    "    def set_constructor_args(self,frame):\n",
    "        #set data members for object from constructor args\n",
    "        _, _, _, params = inspect.getargvalues(frame)\n",
    "        del params[\"frame\"]\n",
    "        for k,v in params.iteritems():\n",
    "            setattr(self,k,v)\n",
    "        \n",
    "        \n",
    "    \n",
    "    def shuffle(self, seed):\n",
    "        inds = np.arange(len(self.filepaths))\n",
    "        np.random.RandomState(seed).shuffle(inds)\n",
    "        '''only shufflez files'''\n",
    "        self.filepaths=self.filepaths[inds]\n",
    "\n",
    "    \n",
    "    #overloading of bracket operators\n",
    "    def __getitem__(self, slice_):\n",
    "        slices = self.convert_slice_to_file_and_ex_inds(slice_)\n",
    "        file_slice = slices[\"file_slice\"]\n",
    "        ex_slice = slices[\"ex_slice\"]\n",
    "        \n",
    "        print file_slice\n",
    "        print ex_slice\n",
    "        filepaths = self.filepaths[file_slice]\n",
    "        tens = self.grab_data_chunk(filepaths)\n",
    "        images = tens[ex_slice]\n",
    "        return images\n",
    "    \n",
    "    def convert_slice_to_file_and_ex_inds(self, slice_):\n",
    "        if isinstance(slice_, slice):\n",
    "            start, stop, step = [getattr(slice_,k) for k in [\"start\", \"stop\", \"step\"]]\n",
    "            assert step==1 or step is None, \"step must be 1 or None\"\n",
    "        \n",
    "        elif isinstance(slice_, int):\n",
    "            start, stop = [slice_, slice_]\n",
    "            \n",
    "        slices =  self.get_file_and_ex_inds(start, stop)\n",
    "        return slices\n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "    def get_file_and_ex_inds(self, start, stop):\n",
    "        #file start stop indices to index filenames\n",
    "        file_start, file_stop = self.get_file_ind(start), self.get_file_ind(stop)\n",
    "        \n",
    "        # get some useful numbers\n",
    "        tot_examples_desired = stop - start \n",
    "        \n",
    "        #relative example indices after examples read in\n",
    "        ex_start = self.get_relative_ex_ind(start)\n",
    "        ex_stop = ex_start + tot_examples_desired\n",
    "        \n",
    "        file_slice = slice(file_start,file_stop + 1)\n",
    "        ex_slice = slice(ex_start,ex_stop)\n",
    "        \n",
    "        return {\"file_slice\":file_slice, \"ex_slice\": ex_slice}\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    def get_file_ind(self,ex_ind):\n",
    "        return ex_ind / self.examples_per_file\n",
    "\n",
    "    def get_relative_ex_ind(self, ex_ind):\n",
    "        return ex_ind % self.examples_per_file\n",
    "        \n",
    "        \n",
    "        \n",
    "    def grab_data_chunk(self, filepaths):\n",
    "        \"\"\"grabs input data (converts filepaths to np tensors)\n",
    "        returns len(filepaths)*4, 16, 768,1152 array\"\"\"\n",
    "        \n",
    "\n",
    "\n",
    "        dataset=MFDataset(filepaths)\n",
    "        \n",
    "        tensor = convert_nc_data_to_tensor(dataset,self.variables, \n",
    "                                           self.time_step_sample_freq, self.time_steps_per_example)\n",
    " \n",
    "        return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice(2, 6, None)\n",
      "slice(0, 3, None)\n"
     ]
    }
   ],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "files = '''cam5_1_amip_run2.cam2.h2.1980-11-05-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-06-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-07-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-08-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-09-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-10-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-11-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-12-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-13-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-14-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-15-00000.nc\n",
    "cam5_1_amip_run2.cam2.h2.1980-11-16-00000.nc'''.split(\"\\n\")\n",
    "\n",
    "filepaths = [join(\"/home/evan/data/climate/input\",fname) for fname in files]\n",
    "\n",
    "ims =ClimateImage(filepaths, time_steps_per_example=1)\n",
    "\n",
    "ex =ims[2:5]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
