{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lasagne\n",
    "import time\n",
    "from nbfinder import NotebookFinder\n",
    "import sys\n",
    "sys.meta_path.append(NotebookFinder())\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib import patches\n",
    "from helper_fxns import early_stop\n",
    "from build_hur_classif_network import build_classif_network\n",
    "from data_loader import load_classification_dataset, load_detection_dataset\n",
    "from print_n_plot import print_train_results,plot_learn_curve,print_val_results, plot_ims_with_boxes\n",
    "from build_hur_detection_network import build_det_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0,len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx: start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield inputs[excerpt], targets[excerpt]\n",
    "\n",
    "def train_one_epoch(x,y,batchsize, train_fn, val_fn):\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(x, y, batchsize, shuffle=True):\n",
    "        inputs, targets = batch\n",
    "        train_err += train_fn(inputs, targets)\n",
    "        _, acc = val_fn(inputs, targets)\n",
    "        train_acc += acc\n",
    "        train_batches += 1\n",
    "    return train_err, train_acc, train_batches\n",
    "\n",
    "def val_one_epoch(x,y,batchsize, val_fn):\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "        for batch in iterate_minibatches(x,y, batchsize, shuffle=False):\n",
    "            inputs, targets = batch\n",
    "            err, acc = val_fn(inputs, targets)\n",
    "            val_err += err\n",
    "            val_acc += acc\n",
    "            val_batches += 1\n",
    "        return val_err, val_acc, val_batches\n",
    "def do_one_epoch(x,y, batchsize, train_fn, val_fn):\n",
    "        start_time = time.time()\n",
    "        tr_err, tr_acc, tr_batches = train_one_epoch(X_train, y_train,\n",
    "                                                     batchsize=batchsize,\n",
    "                                                     train_fn=train_fn,\n",
    "                                                     val_fn=val_fn)\n",
    "                \n",
    "        train_errs.append(tr_err / tr_batches)\n",
    "        train_accs.append(tr_acc / tr_batches)\n",
    "        print_train_results(epoch, num_epochs, start_time, tr_err / tr_batches, tr_acc / tr_batches)\n",
    "        \n",
    "\n",
    "        val_err, val_acc, val_batches = val_one_epoch(X_val, y_val,\n",
    "                                                     batchsize=y_val.shape[0],\n",
    "                                                      val_fn=val_fn)\n",
    "        val_errs.append(val_err / val_batches)\n",
    "        val_accs.append(val_acc / val_batches)\n",
    "        print_val_results(val_err, val_acc / val_batches)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: adding logging\n",
    "#TODO add special way of saving run info based on run number or date or something\n",
    "#TODO add getting weights over updates\n",
    "def train(datasets, num_epochs, mode='classification', save_weights=False, save_plots=False, \n",
    "          frac_of_datasets=1,batchsize=128, network_kwargs={}, inmem_class_network=None, load_path=None):\n",
    "    #todo add in detect\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = datasets\n",
    "    \n",
    "    if batchsize is None or X_train.shape[0] < batchsize:\n",
    "        batchsize = X_train.shape[0]\n",
    "    \n",
    "    if mode=='classification':\n",
    "        train_fn,val_fn,network = build_classif_network(**network_kwargs)\n",
    "    elif mode == 'detection':\n",
    "        if inmem_class_network:\n",
    "            train_fn,val_fn,network, box_fn = build_det_network(inmem_network, **network_kwargs)\n",
    "        elif load_path:\n",
    "            _,_,class_network = build_classif_network(load=True, load_path=load_path)\n",
    "            train_fn,val_fn,network, box_fn = build_det_network(class_network, **network_kwargs)\n",
    "        else:\n",
    "            raise TypeError('must specify either a inmem_classnetwork or a load path for the weights!')\n",
    "        \n",
    "    print \"Starting training...\" \n",
    "    \n",
    "\n",
    "    train_errs, train_accs, val_errs, val_accs = [],[], [], []\n",
    "    for epoch in range(num_epochs):\n",
    "        do_one_epoch(x,y, batchsize, train_fn, val_fn)\n",
    "        \n",
    "\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            plot_learn_curve(train_errs,val_errs, 'err', save_plots=save_plots, mode)\n",
    "            plot_learn_curve(train_accs,val_accs, 'acc', save_plots=save_plots, mode)\n",
    "            if mode == 'detection':\n",
    "                pred_boxes, gt_boxes = box_fn(x_val,y_val)\n",
    "                plot_ims_with_boxes(x_val, pred_bboxes, gt_bboxes, epoch=epoch,save_plots=save_plots)\n",
    "                #plot weights or updates or something \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "\n",
    "\n",
    "        if save_weights and epoch % 10 == 0:\n",
    "        # Optionally, you could now dump the network weights to a file like this:\n",
    "            np.savez('%s.npz'%(mode), *lasagne.layers.get_all_param_values(network))\n",
    "        return network, train_errs[-1], train_accs[-1], val_errs[-1], val_accs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__==\"__main__\":\n",
    "    dataset = load_classification_dataset(num_ims=40)\n",
    "    n = train(dataset,2,batchsize=24, network_kwargs={'num_filters':10,'num_fc_units':128, 'learning_rate': 0.001})\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
